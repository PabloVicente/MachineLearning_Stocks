{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import six\n",
    "import math\n",
    "import time\n",
    "import Quandl\n",
    "import calendar\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import pylab as pylab\n",
    "from docx import Document\n",
    "from datetime import datetime\n",
    "\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "import statsmodels.stats.stattools as stats_stattools\n",
    "import statsmodels.tsa.stattools as tsa_stattools\n",
    "import statsmodels.tsa.seasonal as tsa_seasonal\n",
    "import statsmodels.api as sm \n",
    "import xgboost as xgb\n",
    "from unbalanced_dataset import SMOTE\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import metrics, cross_validation, linear_model, naive_bayes, neighbors, ensemble\n",
    "from sklearn import feature_selection\n",
    "from sklearn import decomposition\n",
    "from sklearn import discriminant_analysis\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from helpers import features_analysis, procces_stocks, data_manipulation, download_quandl_data, ml_dataset, classifier_utils, report_generator, Iteration, Stacking, Boosting\n",
    "\n",
    "fig_size = [10, 6]\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "sb.set_style('darkgrid')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GOLD = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/GOLD.csv')\n",
    "SILVER = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/SILVER.csv')\n",
    "PLAT = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/PLAT.csv')\n",
    "OIL_BRENT = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/OIL_BRENT.csv')\n",
    "\n",
    "USD_GBP = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/USD_GBP.csv')\n",
    "JPY_USD = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/JPY_USD.csv')\n",
    "AUD_USD = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/AUD_USD.csv')\n",
    "\n",
    "INDEX_DJIA = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/INDEX_DJIA.csv')\n",
    "INDEX_HSI = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/INDEX_HSI.csv')\n",
    "INDEX_IBEX = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/INDEX_IBEX.csv')\n",
    "INDEX_N225 = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/INDEX_N225.csv')\n",
    "INDEX_SP500 = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/INDEX_SP500.csv')\n",
    "INDEX_AXJO = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/INDEX_AXJO.csv')\n",
    "INDEX_FCHI = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/INDEX_FCHI.csv')\n",
    "INDEX_GDAXI = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/INDEX_GDAXI.csv')\n",
    "\n",
    "values_names = ['GOLD', 'SILVER', 'PLAT', 'OIL_BRENT', 'USD_GBP', 'JPY_USD', 'AUD_USD', 'DJIA', 'HSI', 'IBEX', 'N225', 'SP500', 'AXJO', 'FCHI', 'GDAXI']\n",
    "values_dfs = [GOLD, SILVER, PLAT, OIL_BRENT, USD_GBP, JPY_USD, AUD_USD, INDEX_DJIA, INDEX_HSI, INDEX_IBEX, INDEX_N225, INDEX_SP500, INDEX_AXJO, INDEX_FCHI, INDEX_GDAXI]\n",
    "values_cols = ['USD', 'Value', 'Open', 'Close', 'High', 'Low', 'Volume']\n",
    "dict_dfs_cols = {}\n",
    "dict_dfs_cols2 = {}\n",
    "\n",
    "for index in range(len(values_names)):\n",
    "    name = values_names[index]\n",
    "    df = values_dfs[index]    \n",
    "    cols = df.columns.values\n",
    "\n",
    "    new_cols = [x for x in cols if x not in ['Date', 'USD', 'Value', 'Open', 'Close', 'High', 'Low', 'Volume']]    \n",
    "    new_cols2 = [x for x in cols if x not in ['Date']]    \n",
    "\n",
    "    dict_dfs_cols[name] = new_cols\n",
    "    dict_dfs_cols2[name] = new_cols2\n",
    "\n",
    "dataset = ml_dataset.generate_df_dataset(values_names, values_dfs, dict_dfs_cols)\n",
    "dataset_all = ml_dataset.generate_df_dataset(values_names, values_dfs, dict_dfs_cols2)\n",
    "\n",
    "\n",
    "\n",
    "#First 30 row\n",
    "dataset = dataset[31:]\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "#colsToShift = [col for col in dataset.columns if 'HSI' in col or'N225' in col or'AXJO' in col]\n",
    "#dataset[colsToShift] = dataset[colsToShift].shift(-1)\n",
    "#last_row = dataset.shape[0]-1\n",
    "#dataset = dataset.drop(last_row, axis=0)  \n",
    "\n",
    "dataset_all = dataset_all[31:]\n",
    "dataset_all = dataset_all.reset_index(drop=True)\n",
    "#dataset_all[colsToShift] = dataset_all[colsToShift].shift(-1)\n",
    "#last_row = dataset_all.shape[0]-1\n",
    "#dataset_all = dataset_all.drop(last_row, axis=0)  \n",
    "\n",
    "#training_dates = Iteration.Iteration('1993-08-19', '2014-12-01')\n",
    "#testing_dates  = Iteration.Iteration('2014-12-02', '2016-04-19')\n",
    "#training_dates.calculate_indices(dataset)\n",
    "#testing_dates.calculate_indices(dataset)\n",
    "#\n",
    "#trainDates = []\n",
    "#testDates = []\n",
    "#trainDates.append(training_dates.lowerIndex)\n",
    "#trainDates.append(training_dates.upperIndex)\n",
    "#testDates.append(testing_dates.lowerIndex)\n",
    "#testDates.append(testing_dates.upperIndex)\n",
    "#    \n",
    "#trainX, trainY, testX, testY, cols = ml_dataset.dataset_to_train_using_dates(dataset, trainDates, testDates, binary=False, shiftFeatures=False, shiftTarget=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "colY = 'IBEX_RD_B10_Close'\n",
    "colsDiff = 10\n",
    "colsToShift = 1\n",
    "#cols = [col for col in dataset.columns if 'HSI' in col or'N225' in col or 'AXJO' in col or 'IBEX' in col]\n",
    "#dataset = dataset[cols]\n",
    "\n",
    "df_x = dataset.filter(regex=('RD_B10_Close'))\n",
    "last_row = list(range(df_x.shape[0] - colsToShift, df_x.shape[0] ))\n",
    "df_x = df_x.drop(last_row, axis=0)\n",
    "#df_x = df_x.drop(colY, axis=1)\n",
    "        \n",
    "df_y = dataset[colY].shift(-colsToShift)\n",
    "last_row = list(range(df_y.shape[0] - colsToShift, df_y.shape[0] ))\n",
    "df_y = df_y.drop(last_row, axis=0)\n",
    "\n",
    "print 'Dataset shape %s' % str(dataset.shape)\n",
    "print 'X shape %s' % str(df_x.shape)\n",
    "print 'Y shape %s' % str(df_y.shape)\n",
    "\n",
    "training_dates = Iteration.Iteration('2008-06-17', '2011-09-01')\n",
    "testing_dates  = Iteration.Iteration('2012-09-04', '2014-10-06')\n",
    "training_dates.calculate_indices(dataset)\n",
    "testing_dates.calculate_indices(dataset)\n",
    "\n",
    "trainDates = []\n",
    "testDates = []\n",
    "trainDates.append(training_dates.lowerIndex)\n",
    "trainDates.append(training_dates.upperIndex)\n",
    "testDates.append(testing_dates.lowerIndex)\n",
    "testDates.append(testing_dates.upperIndex)\n",
    "\n",
    "total = (trainDates[1]-trainDates[0]) + (testDates[1]-testDates[0])\n",
    "tr = float(trainDates[1]-trainDates[0]) / total * 100.0\n",
    "te = float(testDates[1]-testDates[0]) / total * 100.0\n",
    "\n",
    "print \"Training: from %s to %s\" % (str(training_dates.startDate), str(training_dates.endDate))\n",
    "print \"Testing: from %s to %s\" % (str(testing_dates.startDate), str(testing_dates.endDate))\n",
    "print \"%.3f %% training %.3f %% testing\" % (tr,te)\n",
    "print \"%d training %d testing\" % (trainDates[1]-trainDates[0], testDates[1]-testDates[0])        \n",
    "trainX, trainY, testX, testY = ml_dataset.train_arrays_experiments(df_x, df_y, trainDates, testDates)\n",
    "                \n",
    "                \n",
    "#svc = ensemble.RandomForestClassifier(n_jobs=-1, n_estimators=250)\n",
    "svc = svm.LinearSVC()#kernel='poly')\n",
    "#svc = discriminant_analysis.QuadraticDiscriminantAnalysis()\n",
    "#svc = linear_model.LogisticRegression()\n",
    "svc.fit(trainX, trainY)\n",
    "y_pred = svc.predict(testX)\n",
    "print \"Score %s \" % metrics.accuracy_score(testY, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(testY.shape[0]):\n",
    "    print \"## TODAY - %s ##\" % dataset_all.iloc[testing_dates.lowerIndex+i]['Date']\n",
    "    print \"Date %s \\t Close %f \\t Bin %d\" % (dataset_all.iloc[testing_dates.lowerIndex-9+i]['Date'], dataset_all.iloc[testing_dates.lowerIndex-9+i]['IBEX_Close'],dataset_all.iloc[testing_dates.lowerIndex-9+i]['IBEX_RD_B10_Close']) \n",
    "    print \"Date %s \\t Close %f \\t Bin %d\" % (dataset_all.iloc[testing_dates.lowerIndex+i]['Date'], dataset_all.iloc[testing_dates.lowerIndex+i]['IBEX_Close'],dataset_all.iloc[testing_dates.lowerIndex+i]['IBEX_RD_B10_Close'])\n",
    "    print \"Date %s \\t Close %f \\t Bin %d\" % (dataset_all.iloc[testing_dates.lowerIndex+1+i]['Date'], dataset_all.iloc[testing_dates.lowerIndex+1+i]['IBEX_Close'], dataset_all.iloc[testing_dates.lowerIndex+1+i]['IBEX_RD_B10_Close'])\n",
    "    \n",
    "    print \"Test %d \\t Pred %d\" % (testY[i], y_pred[i])\n",
    "    if testY[i] == 1:\n",
    "        print \"El índice SUBE de precio desde el día %s hasta el día %s\" % (dataset_all.iloc[testing_dates.lowerIndex-9+i]['Date'],dataset_all.iloc[testing_dates.lowerIndex+1+i]['Date'])\n",
    "        print \"* BUY shares for day %s *\" % dataset_all.iloc[testing_dates.lowerIndex+1+i]['Date']\n",
    "        #Buy only if today`s price is lower than 10 days ago\n",
    "    else:\n",
    "        print \"El índice BAJA de precio desde el día %s hasta el día %s\" % (dataset_all.iloc[testing_dates.lowerIndex-9+i]['Date'],dataset_all.iloc[testing_dates.lowerIndex+1+i]['Date'])        \n",
    "        print \"* SELL shares for day %s *\" % dataset_all.iloc[testing_dates.lowerIndex+1+i]['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_manipulation.write_csv_data(GOLD, '/Users/Pablo/Desktop/TFM/Data/GOLD.csv')\n",
    "#data_manipulation.write_csv_data(SILVER, '/Users/Pablo/Desktop/TFM/Data/SILVER.csv')\n",
    "#data_manipulation.write_csv_data(PLAT, '/Users/Pablo/Desktop/TFM/Data/PLAT.csv')\n",
    "#data_manipulation.write_csv_data(OIL_BRENT, '/Users/Pablo/Desktop/TFM/Data/OIL_BRENT.csv')\n",
    "#\n",
    "#data_manipulation.write_csv_data(USD_GBP, '/Users/Pablo/Desktop/TFM/Data/USD_GBP.csv')\n",
    "#data_manipulation.write_csv_data(JPY_USD, '/Users/Pablo/Desktop/TFM/Data/JPY_USD.csv')\n",
    "#data_manipulation.write_csv_data(AUD_USD, '/Users/Pablo/Desktop/TFM/Data/AUD_USD.csv')\n",
    "#\n",
    "#data_manipulation.write_csv_data(INDEX_DJIA, '/Users/Pablo/Desktop/TFM/Data/INDEX_DJIA.csv')\n",
    "#data_manipulation.write_csv_data(INDEX_HSI, '/Users/Pablo/Desktop/TFM/Data/INDEX_HSI.csv')\n",
    "#data_manipulation.write_csv_data(INDEX_IBEX, '/Users/Pablo/Desktop/TFM/Data/INDEX_IBEX.csv')\n",
    "#data_manipulation.write_csv_data(INDEX_N225, '/Users/Pablo/Desktop/TFM/Data/INDEX_N225.csv')\n",
    "#data_manipulation.write_csv_data(INDEX_SP500, '/Users/Pablo/Desktop/TFM/Data/INDEX_SP500.csv')\n",
    "#data_manipulation.write_csv_data(INDEX_AXJO, '/Users/Pablo/Desktop/TFM/Data/INDEX_AXJO.csv')\n",
    "#data_manipulation.write_csv_data(INDEX_FCHI, '/Users/Pablo/Desktop/TFM/Data/INDEX_FCHI.csv')\n",
    "#data_manipulation.write_csv_data(INDEX_GDAXI, '/Users/Pablo/Desktop/TFM/Data/INDEX_GDAXI.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
