{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import six\n",
    "import time\n",
    "import Quandl\n",
    "import calendar\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "from pybrain.structure import TanhLayer, SigmoidLayer, SoftmaxLayer\n",
    "from pybrain.datasets import SupervisedDataSet, ClassificationDataSet\n",
    "\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from helpers import features_analysis, procces_stocks, data_manipulation, download_quandl_data, ml_dataset, classifier_utils, report_generator, Iteration, Stacking, Boosting\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GOLD = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/GOLD.csv')\n",
    "SILVER = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/SILVER.csv')\n",
    "PLAT = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/PLAT.csv')\n",
    "OIL_BRENT = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/OIL_BRENT.csv')\n",
    "\n",
    "USD_GBP = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/USD_GBP.csv')\n",
    "JPY_USD = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/JPY_USD.csv')\n",
    "AUD_USD = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/AUD_USD.csv')\n",
    "\n",
    "INDEX_DJIA = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/INDEX_DJIA.csv')\n",
    "INDEX_HSI = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/INDEX_HSI.csv')\n",
    "INDEX_IBEX = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/INDEX_IBEX.csv')\n",
    "INDEX_N225 = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/INDEX_N225.csv')\n",
    "INDEX_SP500 = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/INDEX_SP500.csv')\n",
    "INDEX_AXJO = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/INDEX_AXJO.csv')\n",
    "INDEX_FCHI = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/INDEX_FCHI.csv')\n",
    "INDEX_GDAXI = data_manipulation.read_csv_data('/Users/Pablo/Desktop/TFM/Data/INDEX_GDAXI.csv')\n",
    "\n",
    "values_names = ['GOLD', 'SILVER', 'PLAT', 'OIL_BRENT', 'USD_GBP', 'JPY_USD', 'AUD_USD', 'DJIA', 'HSI', 'IBEX', 'N225', 'SP500', 'AXJO', 'FCHI', 'GDAXI']\n",
    "values_dfs = [GOLD, SILVER, PLAT, OIL_BRENT, USD_GBP, JPY_USD, AUD_USD, INDEX_DJIA, INDEX_HSI, INDEX_IBEX, INDEX_N225, INDEX_SP500, INDEX_AXJO, INDEX_FCHI, INDEX_GDAXI]\n",
    "values_cols = ['USD', 'Value', 'Open', 'Close', 'High', 'Low', 'Volume']\n",
    "dict_dfs_cols = {}\n",
    "dict_dfs_cols2 = {}\n",
    "\n",
    "for index in range(len(values_names)):\n",
    "    name = values_names[index]\n",
    "    df = values_dfs[index]    \n",
    "    cols = df.columns.values\n",
    "\n",
    "    new_cols = [x for x in cols if x not in ['Date', 'USD', 'Value', 'Open', 'Close', 'High', 'Low', 'Volume']]    \n",
    "    new_cols2 = [x for x in cols if x not in ['Date']]    \n",
    "\n",
    "    dict_dfs_cols[name] = new_cols\n",
    "    dict_dfs_cols2[name] = new_cols2\n",
    "\n",
    "dataset = ml_dataset.generate_df_dataset(values_names, values_dfs, dict_dfs_cols)\n",
    "dataset_all = ml_dataset.generate_df_dataset(values_names, values_dfs, dict_dfs_cols2)\n",
    "\n",
    "#First 30 row\n",
    "dataset = dataset[31:]\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "\n",
    "dataset_all = dataset_all[31:]\n",
    "dataset_all = dataset_all.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "colY = 'IBEX_RD_B3_Close'\n",
    "colsDiff = 1\n",
    "colsToShift = 1\n",
    "\n",
    "df_x = dataset.filter(regex=('RD_B3_Close'))\n",
    "last_row = list(range(df_x.shape[0] - colsToShift, df_x.shape[0] ))\n",
    "df_x = df_x.drop(last_row, axis=0)\n",
    "df_x = df_x.drop(colY, axis=1)\n",
    "        \n",
    "df_y = dataset[colY].shift(-colsToShift)\n",
    "last_row = list(range(df_y.shape[0] - colsToShift, df_y.shape[0] ))\n",
    "df_y = df_y.drop(last_row, axis=0)\n",
    "\n",
    "print 'Dataset shape %s' % str(dataset.shape)\n",
    "print 'X shape %s' % str(df_x.shape)\n",
    "print 'Y shape %s' % str(df_y.shape)\n",
    "\n",
    "training_dates = Iteration.Iteration('2008-06-17', '2011-09-01')\n",
    "testing_dates  = Iteration.Iteration('2012-09-04', '2014-10-06')\n",
    "training_dates.calculate_indices(dataset)\n",
    "testing_dates.calculate_indices(dataset)\n",
    "\n",
    "trainDates = []\n",
    "testDates = []\n",
    "trainDates.append(training_dates.lowerIndex)\n",
    "trainDates.append(training_dates.upperIndex)\n",
    "testDates.append(testing_dates.lowerIndex)\n",
    "testDates.append(testing_dates.upperIndex)\n",
    "\n",
    "total = (trainDates[1]-trainDates[0]) + (testDates[1]-testDates[0])\n",
    "tr = float(trainDates[1]-trainDates[0]) / total * 100.0\n",
    "te = float(testDates[1]-testDates[0]) / total * 100.0\n",
    "\n",
    "trainX, trainY, testX, testY = ml_dataset.train_arrays_experiments(df_x, df_y, trainDates, testDates)\n",
    "trainY = trainY.reshape( -1, 1 )  \n",
    "testY = testY.reshape( -1, 1 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = ClassificationDataSet(trainX.shape[1], nb_classes=2, class_labels=['Up','Down'])\n",
    "ds.setField( 'input', trainX )\n",
    "ds.setField( 'target', trainY )\n",
    "#One hot encoding -> DS._convertToOneOfMany()\n",
    "    \n",
    "for hidden_neurons in [10]:\n",
    "\n",
    "    input_size = ds.indim\n",
    "    hidden_size = hidden_neurons\n",
    "    target_size = ds.outdim\n",
    "    validation_proportion = 0.15\n",
    "    epochs = 1000\n",
    "    continue_epochs = 10\n",
    "\n",
    "    print \"Building network...\"\n",
    "    net = buildNetwork(input_size, hidden_size, target_size, bias = True, hiddenclass=TanhLayer, outclass=SigmoidLayer)\n",
    "    #SoftmaxLayer One Hot Encoding\n",
    "    print \"Training network...\"\n",
    "    trainer = BackpropTrainer( net, ds )\n",
    "    train_mse, validation_mse = trainer.trainUntilConvergence( verbose = False, validationProportion = validation_proportion, \n",
    "                                                              maxEpochs = epochs, continueEpochs = continue_epochs )\n",
    "\n",
    "\n",
    "    # Predicions\n",
    "    ds_test = ClassificationDataSet( testX.shape[1], testY.shape[1])\n",
    "    ds_test.setField( 'input', testX )\n",
    "    ds_test.setField( 'target', testY )\n",
    "\n",
    "    # predict\n",
    "    preds = net.activateOnDataset( ds_test)\n",
    "\n",
    "    mse = MSE( testY, preds )\n",
    "    rmse = sqrt( mse )\n",
    "\n",
    "    print \"testing RMSE:\", rmse\n",
    "    mean_preds = np.round_(preds, decimals=0)\n",
    "    print \"score: \", metrics.accuracy_score(testY, mean_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
